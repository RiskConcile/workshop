{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bag of Words </h2> <br>\n",
    "The main idea behind bag of words:\"... the more a words appears the more important it is..\"\n",
    "<br>\n",
    "<h3>without pre-processing </h3><br>\n",
    "In this first example we start with making a bag of words of the unprocessed raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Counter</b> objects.<br> A Counter is a dict subclass for counting hashable objects. It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 3\n",
      "b 2\n",
      "c 1\n",
      "d 1\n",
      "e 0\n"
     ]
    }
   ],
   "source": [
    "#initialize the counter object\n",
    "c = Counter('abcdaab')\n",
    "\n",
    "#loop over the counter object\n",
    "for letter in 'abcde':\n",
    "    print(letter, c[letter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Define the text to processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"The trader is in the pit before the opening of the markets. \\\n",
    "The trader walks in the pit. Everybody screams at the trader.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the counter object with the tokenized text but move the text first to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Counter(word_tokenize(txt.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the 2 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 7), ('.', 3)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.most_common(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above is not useful at all. We clearly need to remove stopwords and punctuations.\n",
    "<br><hr>\n",
    "<h3>with pre-processing</h3>\n",
    "Sequence of actions:\n",
    "<ol>\n",
    "<li>tokenization<br>\n",
    "<li>lowercasing words <br>\n",
    "<li>stemming <br>\n",
    "<li>removing punctuation<br>\n",
    "<li>removing stopwords<br>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function <b>isalpha</b> evaluates to True if the string it is called on contains only characters from the alphabet, otherwise to False <br>\n",
    "The line of code below tokenizes the text in lower case and excludes non-alphabetic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [w for w in word_tokenize(txt.lower()) if w.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tokens we remove the stop words :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokens_no_stopwords = [t for t in tokens if t not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the text using the counter collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trader ( 3 )\n",
      "pit ( 2 )\n"
     ]
    }
   ],
   "source": [
    "a = Counter(tokens_no_stopwords)\n",
    "for n in a.most_common(2):\n",
    "    print(n[0],'(',n[1],')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4>Grouping texts together</h4>\n",
    "<br>\n",
    "\n",
    "The Counter instances support arithmetic and set operations for aggregating results. Imagine we have two count objects c1 and c2:<br>\n",
    "Combined counts:\n",
    "c1 + c2\n",
    "<br>\n",
    "Subtraction: c1 - c2\n",
    "<br>\n",
    "Intersection:c1 & c2\n",
    "<br>\n",
    "Union (taking maximums):c1 | c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_2 = \"There is a lot of activity in the pit. People shout and scream. Tickets are written\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_2 = [w for w in word_tokenize(txt_2.lower()) if w.isalpha()]\n",
    "tokens_no_stopwords_2 = [t for t in tokens_2 if t not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Counter(tokens_no_stopwords_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pit': 1})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a & b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'activity': 1,\n",
       "         'everybody': 1,\n",
       "         'lot': 1,\n",
       "         'markets': 1,\n",
       "         'opening': 1,\n",
       "         'people': 1,\n",
       "         'pit': 3,\n",
       "         'scream': 1,\n",
       "         'screams': 1,\n",
       "         'shout': 1,\n",
       "         'tickets': 1,\n",
       "         'trader': 3,\n",
       "         'walks': 1,\n",
       "         'written': 1})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a + b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'everybody': 1,\n",
       "         'markets': 1,\n",
       "         'opening': 1,\n",
       "         'pit': 1,\n",
       "         'screams': 1,\n",
       "         'trader': 3,\n",
       "         'walks': 1})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a -b\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
